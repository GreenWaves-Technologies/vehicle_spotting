{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from PIL import Image\n",
    "#import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "if int(tf.__version__[0]) < 2:\n",
    "    tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download COCO dataset and distill visualwakewords for the interested classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 download_and_convert_data \\\n",
    "    --dataset_name='visualwakewords' \\\n",
    "    --dataset_dir='visualwakewords_vehicle' \\\n",
    "    --small_object_area_threshold=0.05 \\\n",
    "    --download=False \\\n",
    "    --foreground_class_of_interest=['bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat'] \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'visualwakewords_person'\n",
    "train_filenames = [dataset_dir + '/train.record-000{:02d}-of-00100'.format(i) for i in range(100)]\n",
    "val_filenames  = [dataset_dir + '/val.record-0000{:01d}-of-00010'.format(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_filenames)\n",
    "val_dataset = tf.data.TFRecordDataset(val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "  'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "  'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "  'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "  'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "  'image/key/sha256': tf.io.FixedLenFeature([], tf.string),\n",
    "  'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "  'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "  'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "  #'image/object/bbox/xmin': tf.io.FixedLenFeature([], tf.float32),\n",
    "  #'image/object/bbox/xmax': tf.io.FixedLenFeature([], tf.float32),\n",
    "  #'image/object/bbox/ymin': tf.io.FixedLenFeature([], tf.float32),\n",
    "  #'image/object/bbox/ymax': tf.io.FixedLenFeature([], tf.float32),\n",
    "  #'image/object/area': tf.io.FixedLenFeature([], tf.float32)\n",
    "  }\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "parsed_train_dataset = train_dataset.map(_parse_image_function)\n",
    "parsed_val_dataset = val_dataset.map(_parse_image_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "for example in parsed_train_dataset:\n",
    "    train_labels.append(int(example['image/class/label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for example in parsed_val_dataset:\n",
    "    val_labels.append(int(example['image/class/label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sample for train: 82783 val: 40504\n",
      "Total number of images with vehicle in train: 26476 val: 12674\n"
     ]
    }
   ],
   "source": [
    "print('Total number of sample for train: {} val: {}'.format(len(train_labels), len(val_labels)))\n",
    "print('Total number of images with vehicle in train: {} val: {}'.format(sum(train_labels), sum(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('./visualwakewords_person/visualwakewords/annotations/instances_train2014.json') as f:\n",
    "    coco_annotations_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 1, 'file_name': 'COCO_train2014_000000445327.jpg', 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000445327.jpg', 'height': 480, 'width': 640, 'date_captured': '2013-11-19 20:30:31', 'flickr_url': 'http://farm8.staticflickr.com/7210/6815871618_23be7190bf_z.jpg', 'id': 445327}\n",
      "[8, 1, 1, 1, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 1, 52, 52]\n",
      "['truck', 'person', 'person', 'person', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'banana', 'person', 'banana', 'banana']\n"
     ]
    }
   ],
   "source": [
    "for i,elem in enumerate(coco_annotations_dict['images']):\n",
    "    if elem['file_name'] == 'COCO_train2014_000000445327.jpg':\n",
    "    #if i>10:\n",
    "    #    break\n",
    "        print(elem)\n",
    "        id = elem['id']\n",
    "        objects = []\n",
    "        for ann in coco_annotations_dict['annotations']:\n",
    "            if ann['image_id'] == id:\n",
    "                objects.append(ann['category_id'])\n",
    "        print(objects)\n",
    "        categories = []\n",
    "        for obj in objects:\n",
    "            for categ in coco_annotations_dict['categories']:\n",
    "                if categ['id'] == obj:\n",
    "                    categories.append(categ['name'])\n",
    "        print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
